# v pripade oboustranne alternativy pridam jeste druhou skupinu hodnot
#   - symetricky podle testove statistiky T
#	U otazky typu: Muze byt populacni prumer vysky matek 168 cm?
#   H0: vyska matek = 168 cm vs. H1: vyska matek <> 168 cm
xx2<-c(-T,-T,seq(-T,4,by=0.1),4,-T)
yy2<-c(0,dt(c(-T,seq(-T,4,by=0.1)),length(prom1)-1),0,0)
polygon(xx2,yy2,density=40,col="green")
power.examp()
power.examp(diff=3)
power.examp(n=25)
power.examp(alpha=0.1)
## Lisi se u porodni hmotnost mezi pohlavimi (por.hmnotnost, pohlavi)?
cislo<-Kojeni2$por.hmotnost
kategorie<-Kojeni2$Hoch
# Normalita se testuje pro kazdou skupinu zvlast
#   H0: data maji normalni rozdeleni vs. H1: data nemaji normalni rozdeleni
par(mfrow=c(1,2))
tapply(cislo,kategorie,PlotQQ)
par(mfrow=c(1,1))
# body lezi v obou pripadech priblizne na primce
tapply(cislo,kategorie,shapiro.test)
# obe p-hodnoty vetsi nez alfa -> nezamitame H0,
#   data maji normalni rozdeleni -> pouziji t-test
# nejprve graficke zobrazeni
boxplot(cislo~kategorie,main="Porodni hmotnost podle pohlavi",col=c(2,4))
var.test(cislo~kategorie)
t.test(cislo~kategorie,var.eq=T)
t.test(cislo~kategorie,mu=0,alternative="two.sided",var.eq=T)
# Normalita se testuje pro kazdou skupinu zvlast
#   H0: data maji normalni rozdeleni vs. H1: data nemaji normalni rozdeleni
par(mfrow=c(1,2))
tapply(cislo,kategorie,PlotQQ)
par(mfrow=c(1,1))
# Jsou rozptyly shodne?
# H0: rozptyly se nelisi; H1: rozptyly se lisi
var.test(cislo~kategorie)
## Lisi se u porodni hmotnost mezi pohlavimi (por.hmnotnost, pohlavi)?
cislo<-Kojeni2$por.hmotnost
kategorie<-Kojeni2$Hoch
# Testuju normalitu
# Normalita se testuje pro kazdou skupinu zvlast
# QQ-ploty
par(mfrow=c(1,2))
tapply(cislo,kategorie,PlotQQ)
par(mfrow=c(1,1))
# Shapiro-wilk
tapply(cislo,kategorie,shapiro.test)
# Boxplot ať zjistíme okometricky víc informací
boxplot(cislo~kategorie,main="Porodni hmotnost podle pohlavi",col=c(2,4))
# Testuju shodnost rozptylů
var.test(cislo~kategorie) # test shodnosti rozptylů
# H0: rozptyly se nelisi; H1: rozptyly se lisi
# p-hodnota = 0.886 > alfa (0.05) -> nezamitame H0 (Rozptyly jsou shodne)
# Dvouvýběrový t-test
t.test(cislo~kategorie,var.eq=T) # Shodné rozptyly
#t.test(cislo~kategorie,var.eq=F) # Neshodné rozptyly
## Lisi se u porodni hmotnost mezi pohlavimi (por.hmnotnost, pohlavi)?
cislo<-Kojeni2$por.hmotnost
kategorie<-Kojeni2$Hoch
# Testuju normalitu
# Normalita se testuje pro kazdou skupinu zvlast
# QQ-ploty
par(mfrow=c(1,2))
tapply(cislo,kategorie,PlotQQ)
par(mfrow=c(1,1))
# Shapiro-wilk
tapply(cislo,kategorie,shapiro.test)
# Boxplot ať zjistíme okometricky víc informací
boxplot(cislo~kategorie,main="Porodni hmotnost podle pohlavi",col=c(2,4))
# Testuju shodnost rozptylů
var.test(cislo~kategorie) # test shodnosti rozptylů
# H0: rozptyly se nelisi; H1: rozptyly se lisi
# p-hodnota = 0.886 > alfa (0.05) -> nezamitame H0 (Rozptyly jsou shodne)
# Dvouvýběrový t-test
t.test(cislo~kategorie,var.eq=T) # Shodné rozptyly
#t.test(cislo~kategorie,var.eq=F) # Neshodné rozptyly
t.test(cislo~kategorie,mu=0,alternative="two.sided",var.eq=T)
t.test(cislo~kategorie,var.eq=T)
## Lisi se vek maminek v Praze a na venkove (vekM, Porodnice)?
cislo<-Kojeni2$vekM
kategorie<-Kojeni2$Porodnice
# Testuju normalitu
# Normalita se testuje pro kazdou skupinu zvlast
# QQ-ploty
par(mfrow=c(1,2))
tapply(cislo,kategorie,PlotQQ)
par(mfrow=c(1,1))
# Shapiro-wilk
tapply(cislo,kategorie,shapiro.test)
var.test(cislo~kategorie)
# p-hodnota = 0.6589 > alfa (0.05) -> nezamitame H0
# predpoklad shody rozptylu je splnen
wilcox.test(cislo~kategorie)
# p-hodnota = 0.09097 > alfa (0.05) -> nezamitame H0
#   neprokazalo se, ze by se vek matek v Praze a na venkove vyznamne lisil.
load("C:/Users/popa4/OneDrive/Plocha/PSM ultimate bundle/hod2/Kojeni2.RData")
force(mtcars)
force(mtcars)
force(mtcars)
library(DescTools)
library(DescTools)
# Lisi se cas, za nejz ujedou auta 1/4 mile podle poctu valcu?
cislo<-mtcars$qsec
kategorie<-as.factor(mtcars$cyl)
# Normalita se testuje pro residua linearniho modelu
#   H0: data maji normalni rozdeleni vs. H1: data nemaji normalni rozdeleni
res<-residuals(lm(cislo~kategorie))
PlotQQ(res)
# body lezi priblizne na primce - data maji priblizne normalni rozdeleni
# Kdo chce, muze i ciselny test, ale neni nutne
shapiro.test(res)
# p-hodnota 0.1432 > alfa -> nezamitame H0,
#   data maji priblizne normalni rozdeleni -> pouziji parametrickou ANOVU
# nejprve graficke zobrazeni
boxplot(cislo~kategorie,main="Cas podle poctu valcu",col="orange")
# cas s poctem valcu klesa
# testujeme hypotezy
# H0: vsechny skupiny jsou stejne;  H1: alespon jedna skupina se lisi
# H0: cas na poctu valcu nezavisi; H1: cas na poctu valcu zavisi
# Opet je treba otestovat shodu rozptylu
# dle vysledku se voli typ ANOVy
# Test shody rozptylu
# H0: rozptyly se nelisi; H1: rozptyly se lisi
bartlett.test(cislo~kategorie)
# p-hodnota = 0.4554 > alfa (0.05) -> nezamitame H0
#   rozptyly jsou priblizne shodne, pouzijeme klasickou ANOVu
anova(aov(cislo~kategorie))
# tabulka analyzy rozptylu
# p-hodnota = 0.001955 < alfa (0.05) -> zamitame H0, plati H1
#   cas se podle poctu valcu lisi
# Muze prijit doplnujici otazka: ktere dvojice skupin se od sebe vyznamne lisi?
# parove srovnani
TukeyHSD(aov(cislo~kategorie))
# jen 8 valcu a 4 valce
plot(TukeyHSD(aov(cislo~kategorie)))
res<-residuals(lm(cislo~kategorie))
PlotQQ(res)
shapiro.test(res)
boxplot(cislo~kategorie,main="Cas podle poctu valcu",col="orange")
# Lisi se cas, za nejz ujedou auta 1/4 mile podle poctu valcu?
cislo<-mtcars$qsec
kategorie<-as.factor(mtcars$cyl)
# Normalita se testuje pro residua linearniho modelu
#   H0: data maji normalni rozdeleni vs. H1: data nemaji normalni rozdeleni
res<-residuals(lm(cislo~kategorie))
PlotQQ(res)
# body lezi priblizne na primce - data maji priblizne normalni rozdeleni
# Kdo chce, muze i ciselny test, ale neni nutne
shapiro.test(res)
# p-hodnota 0.1432 > alfa -> nezamitame H0,
#   data maji priblizne normalni rozdeleni -> pouziji parametrickou ANOVU
# nejprve graficke zobrazeni
boxplot(cislo~kategorie,main="Cas podle poctu valcu",col="orange")
# cas s poctem valcu klesa
# testujeme hypotezy
# H0: vsechny skupiny jsou stejne;  H1: alespon jedna skupina se lisi
# H0: cas na poctu valcu nezavisi; H1: cas na poctu valcu zavisi
# Test shody rozptylu
# U ANOVY se používá bartlett test
# dle vysledku se voli typ ANOVy
# Test shody rozptylu
# H0: rozptyly se nelisi; H1: rozptyly se lisi
bartlett.test(cislo~kategorie)
# p-hodnota = 0.4554 > alfa (0.05) -> nezamitame H0
#   rozptyly jsou priblizne shodne, pouzijeme klasickou ANOVu
anova(aov(cislo~kategorie))
# tabulka analyzy rozptylu
# p-hodnota = 0.001955 < alfa (0.05) -> zamitame H0, plati H1
#   cas se podle poctu valcu lisi
# Lisi se cas, za nejz ujedou auta 1/4 mile podle poctu valcu?
cislo<-mtcars$qsec
kategorie<-as.factor(mtcars$cyl)
# Normalita se testuje pro residua linearniho modelu
#   H0: data maji normalni rozdeleni vs. H1: data nemaji normalni rozdeleni
res<-residuals(lm(cislo~kategorie))
PlotQQ(res)
# body lezi priblizne na primce - data maji priblizne normalni rozdeleni
# Kdo chce, muze i ciselny test, ale neni nutne
shapiro.test(res)
# p-hodnota 0.1432 > alfa -> nezamitame H0,
#   data maji priblizne normalni rozdeleni -> pouziji parametrickou ANOVU
# nejprve graficke zobrazeni
boxplot(cislo~kategorie,main="Cas podle poctu valcu",col="orange")
# cas s poctem valcu klesa
# testujeme hypotezy
# H0: vsechny skupiny jsou stejne;  H1: alespon jedna skupina se lisi
# H0: cas na poctu valcu nezavisi; H1: cas na poctu valcu zavisi
# Test shody rozptylu
# U ANOVY se používá bartlett test
# dle vysledku se voli typ ANOVy
# Test shody rozptylu
# H0: rozptyly se nelisi; H1: rozptyly se lisi
bartlett.test(cislo~kategorie)
# p-hodnota = 0.4554 > alfa (0.05) -> nezamitame H0
#   rozptyly jsou priblizne shodne, pouzijeme klasickou ANOVu
anova(aov(cislo~kategorie))
# tabulka analyzy rozptylu
# p-hodnota = 0.001955 < alfa (0.05) -> zamitame H0, plati H1
#   cas se podle poctu valcu lisi
# POKUD by  nebylo normální rozdělení, nebo neshodné rozptyly tak by se použila neparametrická verze anovy
kruskal.test(cislo ~ kategorie)
# Muze prijit doplnujici otazka: ktere dvojice skupin se od sebe vyznamne lisi?
# parove srovnani
TukeyHSD(aov(cislo~kategorie))
# jen 8 valcu a 4 valce
plot(TukeyHSD(aov(cislo~kategorie)))
TukeyHSD(aov(cislo~kategorie))
plot(TukeyHSD(aov(cislo~kategorie)))
# testujeme hypotezy
# H0: vsechny skupiny jsou stejne;  H1: alespon jedna skupina se lisi
# H0: cas na poctu valcu nezavisi; H1: cas na poctu valcu zavisi
# Test shody rozptylu
# U ANOVY se používá bartlett test
# dle vysledku se voli typ ANOVy
# Test shody rozptylu
# H0: rozptyly se nelisi; H1: rozptyly se lisi
bartlett.test(cislo~kategorie)
# p-hodnota = 0.4554 > alfa (0.05) -> nezamitame H0
#   rozptyly jsou priblizne shodne, pouzijeme klasickou ANOVu
# Analyza rozptylu pro pripad, ze se lisi variabilita ve skupinach
oneway.test(cislo~kategorie, var.equal = FALSE)
anova(aov(cislo~kategorie))
# tabulka analyzy rozptylu
# p-hodnota = 0.001955 < alfa (0.05) -> zamitame H0, plati H1
#   cas se podle poctu valcu lisi
load("C:/Users/popa4/OneDrive/Plocha/PSM ultimate bundle/hod3/Stulong.RData")
kat1<-mtcars$cyl
kat2<-mtcars$am
table(kat1,kat2)
addmargins(table(kat1, kat2))
plot(as.factor(kat1)~as.factor(kat2),col=2:4,main="souvislost poctu valcu a typu prevodovky")
## Souvisi spolu pocet valcu a typ prevodovky?
kat1<-mtcars$cyl
kat2<-mtcars$am
table(kat1,kat2)
addmargins(table(kat1, kat2))
# Umime i obrazek?
plot(as.factor(kat1)~as.factor(kat2),col=2:4,main="souvislost poctu valcu a typu prevodovky")
# testujeme H0: pocet valcu a typ prevodovky spolu nesouvisi
#   H1: pocet valcu a typ prevodovky spolu souvisi
chisq.test(kat1,kat2)
# p-hodnota 0.01265 < alfa 0.05 => zamitame H0
# Pocet valcu a typ prevodovky spolu souvisi.
# Ale pozor(!) warning nam rika, ze nejsou splneny predpoklady pouziti chi-kvadrat testu
chisq.test(kat1,kat2)$ex
# jedna ocekavana cetnost je mensi nez 5
## Souvisi spolu pocet valcu a typ prevodovky?
kat1<-mtcars$cyl
kat2<-mtcars$am
table(kat1,kat2)
addmargins(table(kat1, kat2))
# Umime i obrazek?
plot(as.factor(kat1)~as.factor(kat2),col=2:4,main="souvislost poctu valcu a typu prevodovky")
# testujeme H0: pocet valcu a typ prevodovky spolu nesouvisi
#   H1: pocet valcu a typ prevodovky spolu souvisi
chisq.test(kat1,kat2)
# p-hodnota 0.01265 < alfa 0.05 => zamitame H0
# Pocet valcu a typ prevodovky spolu souvisi.
# Ale pozor(!) warning nam rika, ze nejsou splneny predpoklady pouziti chi-kvadrat testu
chisq.test(kat1,kat2)$ex
# jedna ocekavana cetnost je mensi nez 5
# Pro ty same hypotezy pouzijeme Fisheruv exaktni test
fisher.test(kat1,kat2)
library(effectsize)
par(mfrow=c(1,2))
tapply(ciselna,kategoricka,PlotQQ)
install.packages("effectsize")
library(effectsize)
library(DescTools)
## Je vyznamny rozdil ve vysce mezi starsimi a mladsimi muzi? (promenne vyska, VekK)
ciselna<-Stulong$vyska
kategoricka<-Stulong$VekK
par(mfrow=c(1,2))
tapply(ciselna,kategoricka,PlotQQ)
par(mfrow=c(1,2))
tapply(ciselna,kategoricka,PlotQQ)
### Statistiky vecne vyznamnosti
cohens_d(ciselna~kategoricka)
interpret_cohens_d(cohens_d(ciselna~kategoricka))
cislo<-mtcars$qsec
kategorie<-as.factor(mtcars$cyl)
interpret_cohens_d(cohens_d(cislo~kategoricka))
## Souvisi spolu diagnosticka Skupina a vek muzu (promenne Skupina, VekK)
kat1<-Stulong$Skupina
kat2<-Stulong$VekK
(tab<-table(kat1,kat2))
plot(as.factor(kat1)~as.factor(kat2),col=2:5)
chisq.test(kat1,kat2)
# je rozdil ve skupinach skutecne podstatny?
chisq_to_cramers_v(chisq.test(tab)$statistic,
n = sum(tab),
nrow = nrow(tab),
ncol = ncol(tab)
)
# Cramerovo V
sqrt(chisq.test(tab)$statistic/(sum(tab)*(ncol(tab)-1)))
## Souvisi spolu konzumace vina a vek muzu (promenne vino, VekK)
kat1<-Stulong$vino
kat2<-Stulong$VekK
(tab<-table(kat1,kat2))
cislo1<- Stulong$vaha
cislo2<-Stulong$chlst
plot(cislo1~cislo2,pch=19,main="Souvislost vahy a hladiny cholesterolu")
load("C:/Users/popa4/OneDrive/Plocha/PSM ultimate bundle/hod3/Stulong.RData")
cislo1<- Stulong$vaha
cislo2<-Stulong$chlst
plot(cislo1~cislo2,pch=19,main="Souvislost vahy a hladiny cholesterolu")
cislo1<- Stulong$vaha
cislo2<-Stulong$chlst
plot(cislo1~cislo2,pch=19,main="Souvislost vahy a hladiny cholesterolu")
View(Stulong)
cislo1<- Stulong$váha
plot(cislo1~cislo2,pch=19,main="Souvislost vahy a hladiny cholesterolu")
## Mnohorozmerny dvouvyberovy T-test (Hotellingovo T2)
library(DescTools)
# nacteni knihovny
# Porovnavame 2 vyucujici na zaklade hodnoceni jejich studentu.
#   Je mezi vyucujicimi vyznamny rozdil?
matematici <- data.frame(ucitel = factor(rep(1:2, c(5, 7))),
spokojenost = c(1, 3, 2, 4, 3, 2, 6, 4, 5, 5, 3, 4),
znalost = c(4, 7, 2, 6, 3, 6, 6, 8, 7, 10, 9, 6))
# vytvoreni dat
matematici
# ukazka dat
tapply(matematici$spokojenost,matematici$ucitel,mean)
tapply(matematici$znalost,matematici$ucitel,mean)
# prumerna spokojenost a znalost u jednotlivych ucitelu
# jednorozmerne porovnani
boxplot(matematici$spokojenost~matematici$ucitel)
boxplot(matematici$znalost~matematici$ucitel)
t.test(matematici$spokojenost~matematici$ucitel)
t.test(matematici$znalost~matematici$ucitel)
(m1 <- HotellingsT2Test(cbind(matematici$spokojenost, matematici$znalost) ~ matematici$ucitel))
## Mnohorozmerny dvouvyberovy T-test (Hotellingovo T2)
library(DescTools)
# nacteni knihovny
# Porovnavame 2 vyucujici na zaklade hodnoceni jejich studentu.
#   Je mezi vyucujicimi vyznamny rozdil?
matematici <- data.frame(ucitel = factor(rep(1:2, c(5, 7))),
spokojenost = c(1, 3, 2, 4, 3, 2, 6, 4, 5, 5, 3, 4),
znalost = c(4, 7, 2, 6, 3, 6, 6, 8, 7, 10, 9, 6))
# vytvoreni dat
matematici
# ukazka dat
tapply(matematici$spokojenost,matematici$ucitel,mean)
tapply(matematici$znalost,matematici$ucitel,mean)
# prumerna spokojenost a znalost u jednotlivych ucitelu
# jednorozmerne porovnani
boxplot(matematici$spokojenost~matematici$ucitel)
boxplot(matematici$znalost~matematici$ucitel)
t.test(matematici$spokojenost~matematici$ucitel)
t.test(matematici$znalost~matematici$ucitel)
# u znalosti vychazi vyznamny rozdil, u spokojenosti ne
(m1 <- HotellingsT2Test(cbind(matematici$spokojenost, matematici$znalost) ~ matematici$ucitel))
# porovnani obou hodnoceni u ucitelu
## MANOVA - jak se vytvari plasticky film
# vytvoreni dat
trhliny <- c(6.5, 6.2, 5.8, 6.5, 6.5, 6.9, 7.2, 6.9, 6.1, 6.3, 6.7, 6.6, 7.2, 7.1, 6.8, 7.1, 7.0, 7.2, 7.5, 7.6)
lesk <- c(9.5, 9.9, 9.6, 9.6, 9.2, 9.1, 10.0, 9.9, 9.5, 9.4, 9.1, 9.3, 8.3, 8.4, 8.5, 9.2, 8.8, 9.7, 10.1, 9.2)
sytost <- c(4.4, 6.4, 3.0, 4.1, 0.8, 5.7, 2.0, 3.9, 1.9, 5.7, 2.8, 4.1, 3.8, 1.6, 3.4, 8.4, 5.2, 6.9, 2.7, 1.9)
Y <- cbind(trhliny, lesk, sytost)
# zavisle promenna se sklada ze tri dilcich promennych
pomer <- factor(gl(2,10), labels=c("Nizky", "Vysoky"))
prisady <- factor(gl(2, 5, length=20), labels=c("Nizky", "Vysoky"))
# dva nezavisle faktory ... tri zavisle promenne se budou porovnavat v techto skupinach
(fit <- manova(Y ~ pomer * prisady))
# vlastni model - na vystupu jsou soucty ctvercu pro kazdou promennou
summary.aov(fit)
# tabulky jednorozmernych analyz rozptylu pro kazdou promennou zvlast
# na nezavisle promennych zavisi jen trhliny a lesk
summary(fit, test="Wilks")
# existuje nekolik testovych statistik na nichz je zalozena mnohorozmerna analyza rozptylu
# R-ko nabizi statistiky: "Pillai", "Wilks", "Hotelling-Lawley", "Roy"
# Wilkovo lambda je zobecnenim klasicke F-statistiky z jednorozmerne ANOVy
summary(fit)
summary(fit, test="Hotelling-Lawley")
# pouziti jine testove statistiky
# interakce nejsou vyznamne
(fit2 <- manova(Y ~ pomer + prisady))
summary(fit2)
# mira vlivu samostatnych promennych
# Metoda hlavnich komponent
v1 <- c(1,1,1,1,1,1,1,1,1,1,3,3,3,3,3,4,5,6)
v2 <- c(1,2,1,1,1,1,2,1,2,1,3,4,3,3,3,4,6,5)
v3 <- c(3,3,3,3,3,1,1,1,1,1,1,1,1,1,1,5,4,6)
v4 <- c(3,3,4,3,3,1,1,2,1,1,1,1,2,1,1,5,6,4)
v5 <- c(1,1,1,1,1,3,3,3,3,3,1,1,1,1,1,6,4,5)
v6 <- c(1,1,1,2,1,3,3,3,4,3,1,1,1,2,1,6,5,4)
vmat <- data.frame(v1,v2,v3,v4,v5,v6)
m1 <- cbind(v1,v2,v3,v4,v5,v6)
# vytvoreni dat
# Zakladem analyzy hlavnich komponent je korelacni matice
cor(m1)
# korelacni matice
eigen(cor(m1))
# vlastni cisla a vlastni vektory korelacni matice
screeplot(princomp(m1),type="l")
abline(h=1,col="green")
# Pocet hlavnich komponent
# dostatecne velke procento vyuzite variability (80%)
cumsum(eigen(cor(m1))$values/sum(eigen(cor(m1))$values))
# prvni 3 komponenty vysvetli pres 90% variability
# pocet vlastnich cisel vetsich nez 1
prcomp(m1)
(PC<-prcomp(vmat,scale=T))
library(DescTools)
# nacteni knihovny
# Porovnavame 2 vyucujici na zaklade hodnoceni jejich studentu.
#   Je mezi vyucujicimi vyznamny rozdil?
matematici <- data.frame(ucitel = factor(rep(1:2, c(5, 7))),
spokojenost = c(1, 3, 2, 4, 3, 2, 6, 4, 5, 5, 3, 4),
znalost = c(4, 7, 2, 6, 3, 6, 6, 8, 7, 10, 9, 6))
# jednorozmerne porovnani
boxplot(matematici$spokojenost~matematici$ucitel)
boxplot(matematici$znalost~matematici$ucitel)
t.test(matematici$spokojenost~matematici$ucitel)
t.test(matematici$znalost~matematici$ucitel)
# u znalosti vychazi vyznamny rozdil, u spokojenosti ne
(m1 <- HotellingsT2Test(cbind(matematici$spokojenost, matematici$znalost) ~ matematici$ucitel))
# porovnani obou hodnoceni u ucitelu
# vytvoreni dat
trhliny <- c(6.5, 6.2, 5.8, 6.5, 6.5, 6.9, 7.2, 6.9, 6.1, 6.3, 6.7, 6.6, 7.2, 7.1, 6.8, 7.1, 7.0, 7.2, 7.5, 7.6)
lesk <- c(9.5, 9.9, 9.6, 9.6, 9.2, 9.1, 10.0, 9.9, 9.5, 9.4, 9.1, 9.3, 8.3, 8.4, 8.5, 9.2, 8.8, 9.7, 10.1, 9.2)
sytost <- c(4.4, 6.4, 3.0, 4.1, 0.8, 5.7, 2.0, 3.9, 1.9, 5.7, 2.8, 4.1, 3.8, 1.6, 3.4, 8.4, 5.2, 6.9, 2.7, 1.9)
Y <- cbind(trhliny, lesk, sytost)
# zavisle promenna se sklada ze tri dilcich promennych
pomer <- factor(gl(2,10), labels=c("Nizky", "Vysoky"))
prisady <- factor(gl(2, 5, length=20), labels=c("Nizky", "Vysoky"))
# dva nezavisle faktory ... tri zavisle promenne se budou porovnavat v techto skupinach
(fit <- manova(Y ~ pomer * prisady))
# vlastni model - na vystupu jsou soucty ctvercu pro kazdou promennou
summary.aov(fit)
# tabulky jednorozmernych analyz rozptylu pro kazdou promennou zvlast
# na nezavisle promennych zavisi jen trhliny a lesk
summary(fit, test="Wilks")
# existuje nekolik testovych statistik na nichz je zalozena mnohorozmerna analyza rozptylu
# R-ko nabizi statistiky: "Pillai", "Wilks", "Hotelling-Lawley", "Roy"
# Wilkovo lambda je zobecnenim klasicke F-statistiky z jednorozmerne ANOVy
summary(fit)
summary(fit, test="Hotelling-Lawley")
# pouziti jine testove statistiky
# interakce nejsou vyznamne
(fit2 <- manova(Y ~ pomer + prisady))
summary(fit2)
# mira vlivu samostatnych promennych
v1 <- c(1,1,1,1,1,1,1,1,1,1,3,3,3,3,3,4,5,6)
v2 <- c(1,2,1,1,1,1,2,1,2,1,3,4,3,3,3,4,6,5)
v3 <- c(3,3,3,3,3,1,1,1,1,1,1,1,1,1,1,5,4,6)
v4 <- c(3,3,4,3,3,1,1,2,1,1,1,1,2,1,1,5,6,4)
v5 <- c(1,1,1,1,1,3,3,3,3,3,1,1,1,1,1,6,4,5)
v6 <- c(1,1,1,2,1,3,3,3,4,3,1,1,1,2,1,6,5,4)
vmat <- data.frame(v1,v2,v3,v4,v5,v6)
m1 <- cbind(v1,v2,v3,v4,v5,v6)
# vytvoreni dat
# Zakladem analyzy hlavnich komponent je korelacni matice
cor(m1)
# korelacni matice
eigen(cor(m1))
# vlastni cisla a vlastni vektory korelacni matice
screeplot(princomp(m1),type="l")
abline(h=1,col="green")
# Pocet hlavnich komponent
# dostatecne velke procento vyuzite variability (80%)
cumsum(eigen(cor(m1))$values/sum(eigen(cor(m1))$values))
# prvni 3 komponenty vysvetli pres 90% variability
# pocet vlastnich cisel vetsich nez 1
prcomp(m1)
(PC<-prcomp(vmat,scale=T))
factanal(m1, factors=3)
# faktorova analyza jen prerotuje hlavni komponenty
#	metoda rotace 'varimax' je brana jako zakladni (defaultni)
# vypis loadingu a procent vysvetlene variability
## Faktorova analyza
factanal(m1, factors=3)
# faktorova analyza jen prerotuje hlavni komponenty
#	metoda rotace 'varimax' je brana jako zakladni (defaultni)
# vypis loadingu a procent vysvetlene variability
(sc<-factanal(~v1+v2+v3+v4+v5+v6, factors = 3,scores = "Bartlett")$scores)
# faktorove skory pro jednotliva pozorovani
plot(sc[,1],sc[,2],pch=19, main="Prvni 2 faktory")
pop <- LifeCycleSavings[, 2:3]
oec <- LifeCycleSavings[, -(2:3)]
cancor(pop, oec)
library(MASS)
library(MASS)
## Diskriminacni analyza
Iris <- data.frame(rbind(iris3[,,1], iris3[,,2], iris3[,,3]),Sp = rep(c("s","c","v"), rep(50,3)))
# databaze o trech druzich kosatcu: Setosa (s), Versicolour (c), Virginica (v)
# mereny jsou 4 ukazatele: sepal length & width, petal length & width
#	kalisni a okvetni listek, vzdy delka a sirka
train <- sample(1:150, 75)
# nahodny vyber 75 rostlin z cele databaze
table(Iris$Sp[train])
# vstupni data do diskriminacni analyzy ... rostliny, u nichz presne zname druh
(z <- lda(Sp ~ ., Iris, prior = c(1,1,1)/3, subset = train))
# linearni diskriminacni analyza
# vystup: vstupni (apriori) pravdepodobnosti ... jake je ocekavane zastoupeni skupin v populaci
#	prumery promennych ve skupinach a koeficienty linearnich diskriminacnich funkci
predpovedi<-predict(z, Iris[-train, ])
predpovedi$x
# vysledne hodnoty diskriminacnich funkci
predpovedi$posterior
# pravdepodobnosti zarazeni do jednotlivych populaci
predpovedi$class
# na zaklade vytvorene klasifikacni funkce priradi nova mereni do skupin
#	vybere idealni skupinu + vypocte pravdepodobnosti s nimiz do jednotlivych skupin patri
table(Iris[-train,"Sp"],predpovedi$class)
# klasifikacni tabulka, jak dobre se trefil: v radcich skutecne hodnoty, ve sloupcich predikce
plot(predpovedi$x[,1],predpovedi$x[,2],pch=19,col=predpovedi$class,
main="Graf diskriminacnich funkci",xlab="LD1",ylab="LD2")
legend(9,2.2,legend=c(unique(predpovedi$class)),pch=19,col=1:3)
# graf ukazujici kvalitu klasifikace
