---
title: "Typy testů"
output: html_notebook
---

## 

---
title: "PSM Sešit ULTIMATE"
output: html_notebook
---

```{r}
library(DescTools)
library(TeachingDemos)
force(mtcars)
data(mtcars)
```

# Testy obecně

-   Testování stanoveného tvrzení.

## Nulová hypotéza

-   "=" (lék je stejný jako starý)

## Alternativní hypotéza

-   "\<", "\>", "!=" (nový lék je horší/lepší/jiný než starý)

## **Závěry statistického testu**

-   **Zamítnutí nulové hypotézy**

    -   p je menší než alpha (většinou 0.05)

    -   zamítáme nulovou hypotézu

    -   vede k pravdivosti alternativní hypotézy (ale ne vždycky, záleží na kontextu!!!)

-   **Nezamítnutí nulové hypotézy**

    -   p je větší nebo rovno než alpha

    -   Neprokázalo se nic

# Jednovýběrový T-test

-   Pokud mám **normální rozdělení**

-   Testuje průměrnou hodnotu populace

-   **nulová hypotéza** - průměrná hodnota se rovná mnou zadanému číslu

-   **alternativní hypotéza** - průměrná hodnota je menší nebo větší než mnou zadané číslo

```{r}
#   Na zaklade intervalu spolehlivosti rozhodnete, zda stredni hodnota vysky matek muze byt 164 cm?
prom1<-Kojeni2$vyskaM
MeanCI(prom1)
#mean   lwr.ci   upr.ci 
#166.9697 165.7510 168.1884 
# -> interval spolehlivosti říká, že nemůže

# rozhodnuti by melo byt stejne, jako u jednovyberoveho t-testu
t.test(prom1,mu=164)

#One Sample t-test
#data:  prom1
#t = 4.8358, df = 98, p-value = 4.923e-06 
#alternative hypothesis: true mean is not equal to 164
#95 percent confidence interval:
# 165.7510 168.1884
#sample estimates:
#mean of x 
# 166.9697 
```

-   Jednostranná alternativa

-   nulová - průměrná výška matek je 168

-   alternativní - průměrná výška matek je menší/větší (podle parametru) než 168

```{r}
t.test(prom1,mu=168,alternative="greater") 
# p-hodnota = 0.9517 >= alfa (= 0.05) -> nezamitam H0
# Stredni hodnota vysky matek není větší nez 168 cm.
t.test(prom1,mu=168,alternative="less") 
# p-hodnota = 0.04829 < alfa (= 0.05) -> zamitam H0, plati H1
# Stredni hodnota vysky matek je mensi nez 168 cm.
```

# Shapiro-Wilkův test normality

-   Testuje normalitu rozdělení

-   **Nulová hypotéza** = data pocházejí z normálního rozdělení

-   **Alternativní hypotéza** = p-hodnota \< alpha = data **nejsou** **normálně rozdělena**

    ```{r}
    prom2<-Kojeni2$por.hmotnost

    PlotQQ(prom2) # body lezi priblizne na primce
    shapiro.test(prom2) # p >= alpha (0.16)
    # data jsou normální
    ```

# Jednovýběrový Wilcoxonův test

-   Pokud NEMÁM normální rozdělení

-   Testuje průměrnou hodnotu populace

-   **nulová hypotéza** - průměrná hodnota se rovná mnou zadanému číslu

-   **alternativní hypotéza** - průměrná hodnota je menší nebo větší než mnou zadané číslo

-   "robustní verze jednovýběrového t-testu"

-   Místo průměru se ptám na medián

```{r}
# Jsou matky v prumeru starsi nez 23 let?
prom3<-Kojeni2$vekM
# Nejprve otestujeme normalitu
PlotQQ(prom3) # body lezi na oblouku - mam sesikmene rozdeleni
shapiro.test(prom3) # p-hodnota 0.00134 < alfa => zamitam H0
# i Q-Q plot, i test normality ukazuji, ze promenna nema normalni rozdeleni

# pouzijeme neparametricky test
# Testujeme
#   H0: median vekM = 23 vs. H1: median vekM > 23

# Wilcoxonuv test 
wilcox.test(prom3,mu=23,alternative="greater")
  # p-hodnota 9.807e-09 < alfa 0.05 -> zamitam H0
  # Prokazali jsme, ze stredni hodnota veku matek je vetsi nez 23 let.

```

# Dvouvýběrový t-test

-   K porovnání dvou nezávislých vzorků, aby se zjistilo, zda mají tyto vzorky odlišné průměrné hodnoty.

-   Nejčastěji když zjištuji **statisticky významný rozdíl dvou skupin**

-   Potřebuje **normální rozdělení**

-   **Nulová hypotéza** = průměry obou skupin jsou stejné (nemají statisticky významný rozdíl)

-   **Alternativní hypotéza** = průměry obou skupin nejsou stejné (mají statisticky významný rozdíl)

-   Dva typy

    -   Pokud jsou shodné rozptyly

    -   Pokud nejsou shodné rozptyly

```{r}
cislo<-Kojeni2$por.hmotnost
kategorie<-Kojeni2$Hoch

# Dvouvýběrový t-test
t.test(cislo~kategorie,var.eq=T) # Shodné rozptyly
t.test(cislo~kategorie,var.eq=F) # Neshodné rozptyly
# p < alpha = zamitame H0 (průměry nejsou stejné)
```

# Fisherův test (F-test)

-   Jsou rozptyly dvou nezávislých proměnných shodné?

-   Potřebuje normální rozdělení

-   **Nulová hypotéza** = rozptyly obou skupin jsou stejné

-   **Alternativní hypotéza** = rozptyly obou skupin nejsou stejné

```{r}
cislo<-Kojeni2$por.hmotnost
kategorie<-Kojeni2$Hoch

# Testuju shodnost rozptylů
var.test(cislo~kategorie) # test shodnosti rozptylů 
# H0: rozptyly se nelisi; H1: rozptyly se lisi
# pokud p-hodnota < alfa = rozptyly nejsou shodne
# p-hodnota = 0.886 > alfa (0.05) -> nezamitame H0 
```

# Dvouvýběrový Wilcoxonův test

-   K porovnání dvou nezávislých vzorků, aby se zjistilo, zda mají tyto vzorky odlišné průměrné hodnoty.

-   Nejčastěji když zjištuji **statisticky významný rozdíl dvou skupin**

-   Pro **nenormální rozdělení**

-   **Nulová hypotéza** = průměry obou skupin jsou stejné (nemají **statisticky významný rozdíl**)

-   **Alternativní hypotéza** = průměry obou skupin nejsou stejné (mají **statisticky významný rozdíl**)

-   Dva typy

    -   Pokud jsou shodné rozptyly

    -   Pokud nejsou shodné rozptyly

    -   U použítí funkce v R na tom nezáleží, funcke si to sama rozezná

```{r}
## Lisi se vek maminek v Praze a na venkove (vekM, Porodnice)?
cislo<-Kojeni2$vekM
kategorie<-Kojeni2$Porodnice

# Testuju normalitu
# Normalita se testuje pro kazdou skupinu zvlast
# QQ-ploty
par(mfrow=c(1,2))
tapply(cislo,kategorie,PlotQQ)
par(mfrow=c(1,1))
# Shapiro-wilk
tapply(cislo,kategorie,shapiro.test)
```

```{r}
var.test(cislo~kategorie)
  # p-hodnota = 0.6589 > alfa (0.05) -> nezamitame H0
  # predpoklad shody rozptylu je splnen

wilcox.test(cislo~kategorie)
  # p-hodnota = 0.09097 > alfa (0.05) -> nezamitame H0
  #   neprokazalo se, ze by se vek matek v Praze a na venkove vyznamne lisil.
```

# Bartlettův test

-   Fisherův test pro 3 a víc vzorků

-   Jsou rozptyly 3 a víc vzorků nezávislých proměnných shodné?

-   Potřebuje normální rozdělení

-   **Nulová hypotéza** = rozptyly skupin jsou stejné

-   **Alternativní hypotéza** = rozptyly skupin nejsou stejné

```{r}
cislo<-mtcars$qsec
kategorie<-as.factor(mtcars$cyl)

bartlett.test(cislo~kategorie)
  # p-hodnota = 0.4554 > alfa (0.05) -> nezamitame H0
  #   rozptyly jsou priblizne shodne, pouzijeme klasickou ANOVu
```

# ANOVA

-   Podobně jako dvouvýběrový t-test porovnává střední hodnoty více vzorků

-   Pro 3 a víc vzorků

-   Potřebuje **normální rozdělení reziduí** (residua jsou rozdíly mezi pozorovanými hodnotami a predikovanými hodnotami modelu) nebo normální rozdělení dat v rámci každé skupiny. (Budeme pracovat s rezidui)

-   Nejčastěji když zjištuji **statisticky významný rozdíl dvou skupin**

-   **Nulová hypotéza** = Průměry všech skupin jsou stejné

-   **Alternativní hypotéza** = Průmery všech skupin nejsou stejné

-   Podle shodnosti rozptylu různé typy testu

-   Pokud chci vědět které skupiny se liší použiju **Tukeyův HSD test**

```{r}
cislo<-mtcars$qsec
kategorie<-as.factor(mtcars$cyl)

# Rozptyly jsou různé
oneway.test(cislo~kategorie, var.equal = FALSE) # Welchova Anova
# Rozptyly jsou stejné
anova(aov(cislo~kategorie))

# které skupiny se liší?
TukeyHSD(aov(cislo~kategorie))
  # jen 8 valcu a 4 valce
plot(TukeyHSD(aov(cislo~kategorie)))  
```

# Kruskal-Wallisův test

-   Jako Anova (3+ skupiny - střední hodnoty)

-   Když není normální rozdělení

-   Neřeší jestli jsou rozptyly shodné (jde pro shodné i neshodné)

-   **Nulová hypotéza** = Průměry všech skupin jsou stejné

-   **Alternativní hypotéza** = Průměry všech skupin nejsou stejné

-   Pokud Kruskal zamítne nulovou hypotézu (průměry nejsou stejné) tak použiju DUNNŮV TEST - ten mi poví které dvojice výběrů se liší

```{r}

# POKUD by  nebylo normální rozdělení, nebo neshodné rozptyly tak by se použila neparametrická verze anovy 
kruskal.test(cislo ~ kategorie)
# Ktera dvojice skupin se od sebe vyznamne lisi?

# Dunn test pokud kruskal zjistí, že dvojice výběrů se liší - zjistí která dvojice se liší
DunnTest(cislo~kategorie)
  # Vyznamne se lisi vozy se tremi prevody od ostatnich
```

```{r}
# Lisi se cas, za nejz ujedou auta 1/4 mile podle poctu valcu?
cislo<-mtcars$qsec
kategorie<-as.factor(mtcars$cyl)
  
# Normalita se testuje pro residua linearniho modelu
#   H0: data maji normalni rozdeleni vs. H1: data nemaji normalni rozdeleni
res<-residuals(lm(cislo~kategorie))
PlotQQ(res)
  # body lezi priblizne na primce - data maji priblizne normalni rozdeleni
shapiro.test(res)
  # p-hodnota 0.1432 > alfa -> nezamitame H0, 
  #   data maji priblizne normalni rozdeleni -> pouziji parametrickou ANOVU 
  
# nejprve graficke zobrazeni
boxplot(cislo~kategorie,main="Cas podle poctu valcu",col="orange")
  # cas s poctem valcu klesa
 
# testujeme hypotezy
  # H0: vsechny skupiny jsou stejne;  H1: alespon jedna skupina se lisi
  # H0: cas na poctu valcu nezavisi; H1: cas na poctu valcu zavisi
  
# Test shody rozptylu
# U ANOVY se používá bartlett test
  # dle vysledku se voli typ ANOVy
# Test shody rozptylu
  # H0: rozptyly se nelisi; H1: rozptyly se lisi
bartlett.test(cislo~kategorie)
  # p-hodnota = 0.4554 > alfa (0.05) -> nezamitame H0
  #   rozptyly jsou priblizne shodne, pouzijeme klasickou ANOVu
# Analyza rozptylu pro pripad, ze se lisi variabilita ve skupinach
oneway.test(cislo~kategorie, var.equal = FALSE)

anova(aov(cislo~kategorie))
  # tabulka analyzy rozptylu
  # p-hodnota = 0.001955 < alfa (0.05) -> zamitame H0, plati H1
  #   cas se podle poctu valcu lisi

# POKUD by  nebylo normální rozdělení, nebo neshodné rozptyly tak by se použila neparametrická verze anovy 
kruskal.test(cislo ~ kategorie)
# Ktera dvojice skupin se od sebe vyznamne lisi?
# Dunn test pokud kruskal zjistí, že dvojice výběrů se liší - zjistí která dvojice se liší
DunnTest(cislo~kategorie)
  # Vyznamne se lisi vozy se tremi prevody od ostatnich

# Muze prijit doplnujici otazka: ktere dvojice skupin se od sebe vyznamne lisi?
# parove srovnani
TukeyHSD(aov(cislo~kategorie))
  # jen 8 valcu a 4 valce
plot(TukeyHSD(aov(cislo~kategorie)))  
```

# Chi-kvadrát test

-   Test nezávislosti dvou kategoriálních proměnných

-   Testuje analýzu tabulkových dat, kde chceme zjistit, zda existuje signifikantní vztah mezi dvěma proměnnými na základě jejich pozorovaných četností.

    -   Ve zkratce = existuje vztah mezi proměnnou A a proměnnou B

-   Pro analýzu křížových tabulek, kde jsou data rozdělena do kategorií

-   Potřebuje, aby očekávané četnosti v každé buňce tabulky byly dostatečně velké (např. větší než 5), aby byl test validní.

-   **Nulová hypotéza** = Mezi skupinami neexistuje vztah

-   **Alternativní hypotéza** = Mezi skupinami existuje vztah

-   Dva typy:

    -   Data rozdělena do dvou kategorií = Chi-kvadrát test s jedním stupněm volnosti

    -   Data rozdělena do více kategorií = Chi-kvadrát test s více stupni volnosti

    -   **! R si samo pozná co má použít !**

```{r}
## Souvisi spolu pocet valcu a typ prevodovky?
kat1<-mtcars$cyl
kat2<-mtcars$am
table(kat1,kat2)
addmargins(table(kat1, kat2))
# Umime i obrazek?
plot(as.factor(kat1)~as.factor(kat2),col=2:4,main="souvislost poctu valcu a typu prevodovky")

# testujeme H0: pocet valcu a typ prevodovky spolu nesouvisi
#   H1: pocet valcu a typ prevodovky spolu souvisi
chisq.test(kat1,kat2)
  # p-hodnota 0.01265 < alfa 0.05 => zamitame H0
  # Pocet valcu a typ prevodovky spolu souvisi.
  # Ale pozor(!) warning nam rika, ze nejsou splneny predpoklady pouziti chi-kvadrat testu
chisq.test(kat1,kat2)$ex
  # jedna ocekavana cetnost je mensi nez 5
```

# Fisherův exaktní test

-   Jako chi-kvadrát, ale pro malý vzorky

-   Přesné hodnocení asociace

-   Používá faktoriál

-   **Nulová hypotéza** = Mezi skupinami neexistuje vztah

-   **Alternativní hypotéza** = Mezi skupinami existuje vztah

    ```{r}
    kat1<-mtcars$cyl
    kat2<-mtcars$am
    # testujeme H0: pocet valcu a typ prevodovky spolu nesouvisi
    #   H1: pocet valcu a typ prevodovky spolu souvisi
    fisher.test(kat1,kat2)
    ```

# Věcná významnost

-   Věcná významnost se týká interpretace statistických výsledků z hlediska jejich praktické relevance a dopadu na zkoumaný jev ve skutečném světě.

-   Pomáhá porozumět, zda nalezené rozdíly nebo asociace mezi proměnnými mají praktický význam.

-   Poskytuje informace o tom, jak silné a směrodatné jsou nalezené efekty ve srovnání s celkovou variabilitou dat.

-   Pepovo ez vysvětlení = kontroluješ jak pravdivý máš výsledky

## Cohenovo d

-   Kontrola **t-testu**

-   Míra efektu, která vyjadřuje velikost rozdílu mezi dvěma skupinami ve standardních odchylkách.

```{r}
cislo<-mtcars$qsec
kategorie<-as.factor(mtcars$cyl)

interpret_cohens_d(cohens_d(cislo~kategoricka))
```

## Hedgesovo g

-   Kontrola **t-testu s malými vzorky**

```{=html}
<!-- -->
```
-   Podobné Cohenovu d, ale upraveno pro malé vzorky.

```{r}
interpret_hedges_g(hedges_g(ciselna~kategoricka))
```

## Glassovo delta

-   Kontrola **t-testu**

```{=html}
<!-- -->
```
-   Míra efektu pro porovnání účinků mezi dvěma nezávislými skupinami.

```{r}
interpret_glass_delta(glass_delta(ciselna~kategoricka))
```

#### Fisherovo eta:

-   Kontrola **ANOVA**

```{=html}
<!-- -->
```
-   Míra efektu pro analýzu rozptylu (ANOVA), vyjadřuje velikost efektu ve srovnání s celkovou variabilitou v datech.

```{r}
eta_squared(aov(ciselna~kategoricka))
```

#### Haysova omega

-   Kontrola **ANOVA**

```{=html}
<!-- -->
```
-   Podobné Fisherově etě, ale robustnější vůči porušením předpokladů ANOVA.

```{r}
omega_squared(aov(ciselna~kategoricka))
```

#### Cramerovo V

-   Kontrola **Chi-kvadrát**

```{=html}
<!-- -->
```
-   Používá se k interpretaci síly asociace mezi dvěma kategoriálními proměnnými v kontingenční tabulce.

```{r}
kat1<-Stulong$Skupina
kat2<-Stulong$VekK

(tab<-table(kat1,kat2))
sqrt(chisq.test(tab)$statistic/(sum(tab)*(ncol(tab)-1)))
```

#### Cramerovo phi

-   Kontrola **Chi-kvadrát**

```{=html}
<!-- -->
```
-   Používá se k interpretaci síly asociace mezi dvěma binárními proměnnými v kontingenční tabulce.

```{r}
sqrt(chisq.test(tab)$statistic/sum(tab))
```

```{r}
## Souvisi spolu diagnosticka Skupina a vek muzu (promenne Skupina, VekK)
kat1<-Stulong$Skupina
kat2<-Stulong$VekK

(tab<-table(kat1,kat2))
plot(as.factor(kat1)~as.factor(kat2),col=2:5)
chisq.test(kat1,kat2)
  # je rozdil ve skupinach skutecne podstatny?

chisq_to_cramers_v(chisq.test(tab)$statistic,
             n = sum(tab),
             nrow = nrow(tab),
             ncol = ncol(tab)
)
  # Cramerovo V
  sqrt(chisq.test(tab)$statistic/(sum(tab)*(ncol(tab)-1)))

## Souvisi spolu konzumace vina a vek muzu (promenne vino, VekK)
kat1<-Stulong$vino
kat2<-Stulong$VekK
(tab<-table(kat1,kat2))
plot(as.factor(kat1)~as.factor(kat2),col=2:5)
chisq.test(kat1,kat2)  

chisq_to_phi(chisq.test(tab)$statistic,
             n = sum(tab),
             nrow = nrow(tab),
             ncol = ncol(tab)
)
  # Cramerovo phi
  sqrt(chisq.test(tab)$statistic/sum(tab))
```

# \-\-\-\-\-\-\-\-\-\-\-\-\-\-\-\-\-\-\-\-\-\-\-\-\-\-\-\-\-\-\-\-\-\-\-\-\-\-\-\--

## Hotellingův test

-   Porovnávám střední hodnotu náhodného vektoru ve dvou populacích.

-   Předpokládám nezávislá měření.

-   Nulová hypotéza: vektory středních hodnot se rovnají

-   Používá se v situacích, kdy máme **více než jednu závislou proměnnou** a chceme testovat rozdíly mezi skupinami v těchto proměnných současně.

-   V podstatě dvouvýběrový t-test pro závislé proměnné

```{r}
# Porovnavame 2 vyucujici na zaklade hodnoceni jejich studentu. 
#   Je mezi vyucujicimi vyznamny rozdil?
matematici <- data.frame(ucitel = factor(rep(1:2, c(5, 7))), 
                         spokojenost = c(1, 3, 2, 4, 3, 2, 6, 4, 5, 5, 3, 4), 
                         znalost = c(4, 7, 2, 6, 3, 6, 6, 8, 7, 10, 9, 6))
```

```{r}
# jednorozmerne porovnani
boxplot(matematici$spokojenost~matematici$ucitel)
boxplot(matematici$znalost~matematici$ucitel)
t.test(matematici$spokojenost~matematici$ucitel)
t.test(matematici$znalost~matematici$ucitel)
  # u znalosti vychazi vyznamny rozdil, u spokojenosti ne
(m1 <- HotellingsT2Test(cbind(matematici$spokojenost, matematici$znalost) ~ matematici$ucitel))
  # porovnani obou hodnoceni u ucitelu
```

## MANOVA

-   V podstatě ANOVA pro závislé proměnné

-   Předpokládám nezávislá měření.

-   Nulová hypotéza: vektory středních hodnot se rovnají

-   Testové statistiky pro MANOVU:

    -   **Wilkovo lambda**

    -   **Pillayova stopa**

    -   **Hotellingovo lambda**

```{r}
# vytvoreni dat
trhliny <- c(6.5, 6.2, 5.8, 6.5, 6.5, 6.9, 7.2, 6.9, 6.1, 6.3, 6.7, 6.6, 7.2, 7.1, 6.8, 7.1, 7.0, 7.2, 7.5, 7.6)
lesk <- c(9.5, 9.9, 9.6, 9.6, 9.2, 9.1, 10.0, 9.9, 9.5, 9.4, 9.1, 9.3, 8.3, 8.4, 8.5, 9.2, 8.8, 9.7, 10.1, 9.2)
sytost <- c(4.4, 6.4, 3.0, 4.1, 0.8, 5.7, 2.0, 3.9, 1.9, 5.7, 2.8, 4.1, 3.8, 1.6, 3.4, 8.4, 5.2, 6.9, 2.7, 1.9)
Y <- cbind(trhliny, lesk, sytost)
  # zavisle promenna se sklada ze tri dilcich promennych
pomer <- factor(gl(2,10), labels=c("Nizky", "Vysoky"))
prisady <- factor(gl(2, 5, length=20), labels=c("Nizky", "Vysoky"))
  # dva nezavisle faktory ... tri zavisle promenne se budou porovnavat v techto skupinach
```

```{r}
(fit <- manova(Y ~ pomer * prisady))
  # vlastni model - na vystupu jsou soucty ctvercu pro kazdou promennou
summary.aov(fit)
  # tabulky jednorozmernych analyz rozptylu pro kazdou promennou zvlast
  # na nezavisle promennych zavisi jen trhliny a lesk
summary(fit, test="Wilks")
  # existuje nekolik testovych statistik na nichz je zalozena mnohorozmerna analyza rozptylu
  # R-ko nabizi statistiky: "Pillai", "Wilks", "Hotelling-Lawley", "Roy"
  # Wilkovo lambda je zobecnenim klasicke F-statistiky z jednorozmerne ANOVy
summary(fit)
  summary(fit, test="Hotelling-Lawley")
  # pouziti jine testove statistiky
  # interakce nejsou vyznamne
(fit2 <- manova(Y ~ pomer + prisady))
summary(fit2)
  # mira vlivu samostatnych promennych
```

## Metoda hlavních komponent(PCA)

-   Transformuje vstupní data tak, aby bylo možné snížit jejich dimenzi / pocet.

-   Vstupní data poté reprezentujeme menším množstvím nových promenných **(hlavních komponent)**

-   Jejich optimální počet je počet vlastních čísel korelační matice vetších než 1. (Graficky znázorněno pomocí tzv. " Scree plot")

-   Nevýhodou hlavních komponent je, že nemají přirozenou interpretaci (pokud chceme menší počet proměnných co jde interpretovat použijeme faktorovu analýzu)

```{r}
v1 <- c(1,1,1,1,1,1,1,1,1,1,3,3,3,3,3,4,5,6)
v2 <- c(1,2,1,1,1,1,2,1,2,1,3,4,3,3,3,4,6,5)
v3 <- c(3,3,3,3,3,1,1,1,1,1,1,1,1,1,1,5,4,6)
v4 <- c(3,3,4,3,3,1,1,2,1,1,1,1,2,1,1,5,6,4)
v5 <- c(1,1,1,1,1,3,3,3,3,3,1,1,1,1,1,6,4,5)
v6 <- c(1,1,1,2,1,3,3,3,4,3,1,1,1,2,1,6,5,4)
vmat <- data.frame(v1,v2,v3,v4,v5,v6)
m1 <- cbind(v1,v2,v3,v4,v5,v6)
  # vytvoreni dat
# Zakladem analyzy hlavnich komponent je korelacni matice
cor(m1)
  # korelacni matice
eigen(cor(m1))
  # vlastni cisla a vlastni vektory korelacni matice
screeplot(princomp(m1),type="l")
abline(h=1,col="green")
# Pocet hlavnich komponent
  # dostatecne velke procento vyuzite variability (80%)
  cumsum(eigen(cor(m1))$values/sum(eigen(cor(m1))$values))
    # prvni 3 komponenty vysvetli pres 90% variability
  # pocet vlastnich cisel vetsich nez 1
prcomp(m1)
(PC<-prcomp(vmat,scale=T))
  # hlavni komponenty
  # vrati variabilitu hlavnich komponent spolu s koeficienty jednotlivych komponent
plot(PC)
  # vykresli variabilitu
plot(PC$x[,1],PC$x[,2],pch=19,main="Prvni 2 hlavni komponenty")
  # vykresleni prvnich dvou hlavnich komponent, ukazuji v datech skupiny
# maji hlavni komponenty prirozenou interpretaci?
#   mnohdy ne, pak je potreba pouzit faktorovou analyzu
```

## Faktorová analýza

-   Jako PCA ale jde interpretovat

```{r}
factanal(m1, factors=3) 
  # faktorova analyza jen prerotuje hlavni komponenty
  #	metoda rotace 'varimax' je brana jako zakladni (defaultni) 
  # vypis loadingu a procent vysvetlene variability
(sc<-factanal(~v1+v2+v3+v4+v5+v6, factors = 3,scores = "Bartlett")$scores)
  # faktorove skory pro jednotliva pozorovani
plot(sc[,1],sc[,2],pch=19, main="Prvni 2 faktory")
  # vykresleni prvnich dvou faktoru
```

## Diskriminační analýza

-   Rozděluje data do předem definovaných skupin

-   lineární - oddělí data přímkou

-   kvadratická - oddělí data elipsou

    ```{r}

    library(MASS)

    ## Diskriminacni analyza
    Iris <- data.frame(rbind(iris3[,,1], iris3[,,2], iris3[,,3]),Sp = rep(c("s","c","v"), rep(50,3)))
    # databaze o trech druzich kosatcu: Setosa (s), Versicolour (c), Virginica (v)
    # mereny jsou 4 ukazatele: sepal length & width, petal length & width
    #	kalisni a okvetni listek, vzdy delka a sirka
    train <- sample(1:150, 75)
    # nahodny vyber 75 rostlin z cele databaze
    table(Iris$Sp[train])
    # vstupni data do diskriminacni analyzy ... rostliny, u nichz presne zname druh
    (z <- lda(Sp ~ ., Iris, prior = c(1,1,1)/3, subset = train))
    # linearni diskriminacni analyza
    # vystup: vstupni (apriori) pravdepodobnosti ... jake je ocekavane zastoupeni skupin v populaci 
    #	prumery promennych ve skupinach a koeficienty linearnich diskriminacnich funkci
    predpovedi<-predict(z, Iris[-train, ])
    predpovedi$x
    # vysledne hodnoty diskriminacnich funkci
    predpovedi$posterior
    # pravdepodobnosti zarazeni do jednotlivych populaci
    predpovedi$class
    # na zaklade vytvorene klasifikacni funkce priradi nova mereni do skupin
    #	vybere idealni skupinu + vypocte pravdepodobnosti s nimiz do jednotlivych skupin patri
    table(Iris[-train,"Sp"],predpovedi$class)
    # klasifikacni tabulka, jak dobre se trefil: v radcich skutecne hodnoty, ve sloupcich predikce
    plot(predpovedi$x[,1],predpovedi$x[,2],pch=19,col=predpovedi$class,
         main="Graf diskriminacnich funkci",xlab="LD1",ylab="LD2")
    legend(9,2.2,legend=c(unique(predpovedi$class)),pch=19,col=1:3)
    # graf ukazujici kvalitu klasifikace

    ```

## Shluková analýza

-   K identifikaci přirozených skupin (nebo shluků) v datech na základě podobnosti mezi pozorováními.

### Hierarchická shluková analýza

-   Vytváří hierarchii shluků, tj. stromovou strukturu, kde každé pozorování začíná ve vlastním shluku a postupně se spojuje do větších shluků.

```{r}
## Shlukova analyza
# budem delit americke staty do skupin na zaklade 4 ukazatelu: vrazdy, napadeni, populace, znasilneni
# hierarchicke clusterovani
hc <- hclust(dist(USArrests), "ave")
# average linkage
hc <- hclust(dist(USArrests))
# complete linkage
# vstupem je matice vzdalenosti jednotlivych bodu
plot(hc, hang = -1)
# nakresleni dendrogramu - postup, jak shlukuje
#	nejprve ma kazde pozorovani svou vlastni skupinu, a ty se pak spojuji do vetsich celku
#	mozny je i obraceny postup, tj. od jedne velke skupiny k mnoha malym
seg<-cutree(hc,k=4)
# rozdeli data do 4 skupin
table(seg)
rect.hclust(hc, k=4, border="red")
# zobrazi skupiny do grafu
tapply(USArrests$Murder,as.factor(seg),mean)
# spocita prumery za jednotlive shluky
```

### K-means clustering

-   Algoritmus z USU

-   Náhodný bod -\> k němu nejbližší body -\> přiblížit bod do středu těch bodů -\> opakovat

```{r}
# K-means clustering
require(graphics)
# prace s dvojrozmernymi daty
x <- rbind(matrix(rnorm(100, sd = 0.3), ncol = 2),matrix(rnorm(100, mean = 1, sd = 0.3), ncol = 2))
colnames(x) <- c("x", "y")
# vygenerovani dat
(cl <- kmeans(x, 2))
# rozdeleni dat do dvou segmentu (pocet segmentu vybiram podle 'potreby')
# mohu zkusit vice seskupeni a porovnat je mezi sebou
plot(x, col = cl$cluster,pch=19)
# zakresleni dat rozdelenych do skupin
points(cl$centers, col = 1:2, pch = 8, cex=2,lwd=2)
# zakresleni stredu
```

## Kanonická korelace

-   Máme dve skupiny proměnných X a Y měřených na stejných jedincích a chceme zjistit, zda mezi těmito skupinami je nějaký vztah, případně jaký

-   Kanonická korelace identifikuje lineární kombinace proměnných z obou sad, které mají nejvyšší korelaci.

```{r}
## Kanonicka korelace
#	korelace mezi dvema skupinami promennych
# pracujme s charakteristikami statu: osobni uspory, podil populace do 15 let,
#	podil populace nad 75 let, prijem na obyvatele, narust prijmu na obyvatele
# rozdelime promenne do skupin: populacni podily, ekonomicke charakteristiky
pop <- LifeCycleSavings[, 2:3]
oec <- LifeCycleSavings[, -(2:3)]
cancor(pop, oec)
# vypocet kanonickych korelaci
#	na vystupu jsou kanonicke korelace (jejich pocet je stejny jako 
#	pocet promennych v mensi skupine), koeficienty kanonickych promennych
#	prumery promennych
```
